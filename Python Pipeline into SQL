
#### This file will read a .csv file on desktop, create a dataframe based on it, flatten the matrix data and insert into sql tables

import pandas as pd
import sqlalchemy


file_path = r"C:\Users\RyanDavidson\OneDrive - ConData\Documents\New jasper converted rate sheet - python test.xlsx"


df = pd.read_excel(file_path, sheet_name="Next Day Air", header=None, usecols="C:M", skiprows=8, nrows=155)  #### adjust cell reference here. 


sheet_name = "Next Day Air"

# Drop rows with any empty values in 'Zone', 'Weight (lbs)', or 'Rate'
df = df.dropna(subset=[5, 8, 11])  # Adjust column indices as needed


flattened_df = pd.DataFrame({
    'Service Description': [sheet_name] * df.size,  # New column for sheet name
    'Zone': df.iloc[0].tolist() * df.shape[0],
    'Weight (lbs)': df.iloc[:, 0].repeat(df.shape[1]),
    'Rate': df.values.flatten()
})


server = '10.6.0.7'
database = 'analytics'
username = 'rdavidson'
password = 'RD!new22!'


engine = sqlalchemy.create_engine(f"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server")


dtypes = {
    'Service Description': sqlalchemy.types.VARCHAR(255),
    'Zone': sqlalchemy.types.INT,
    'Weight (lbs)': sqlalchemy.types.DECIMAL(18, 2),
    'Rate': sqlalchemy.types.DECIMAL(18, 2)
}

flattened_df.to_sql('Python_Pipeline_Test', con=engine, if_exists='replace', index=False, dtype=dtypes)

print("Data inserted into SQL Server table.")
